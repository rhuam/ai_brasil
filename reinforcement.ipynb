{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Aprendizado por reforço\n",
    "\n",
    "A documentação necessário das ferramentas usadas podem ser vistitadas em:\n",
    "\n",
    "- [MiniBatchKMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importar conjunto de dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "ambiente = np.matrix([\n",
    "    [-1, -1, -1, -1, -5, -1],\n",
    "    [-1, -1, -1, -1,-10, 10],\n",
    "    [-1, -1, -1, -1, -1, -1],\n",
    "    [-1, -2, -1, -1, -5, -1],\n",
    "    [-1, -5, -1, -1, -2, 100],\n",
    "    [-1, -2, -1, -1, -1, 100],\n",
    "    [-1, -1, -1, -1, -5, -5],\n",
    "])\n",
    "\n",
    "draw = np.matrix([\n",
    "    [' ',' ',' ',' ',' ',' '],\n",
    "    [' ',' ',' ',' ',' ',' '],\n",
    "    [' ',' ',' ',' ',' ',' '],\n",
    "    [' ',' ',' ',' ',' ',' '],\n",
    "    [' ',' ',' ',' ',' ',' '],\n",
    "    [' ',' ',' ',' ',' ',' '],\n",
    "    [' ',' ',' ',' ',' ',' '],\n",
    "    [' ',' ',' ',' ',' ',' ']   \n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "class EpsilonGreedy:\n",
    "\n",
    "    def __init__(self, initial_epsilon=1.0, min_epsilon=0.0, decay=0.999):\n",
    "        self.initial_epsilon = initial_epsilon\n",
    "        self.epsilon = initial_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.decay = decay\n",
    "\n",
    "    def choose(self, q_table, state, action_space):\n",
    "        if np.random.rand() < self.epsilon or sum(q_table[state]) == 0:\n",
    "            action = randint(0, len(action_space) - 1)\n",
    "        else:\n",
    "            try:\n",
    "                action = np.argmax(q_table[state])\n",
    "            except:\n",
    "                action = randint(0, len(action_space) - 1)\n",
    "\n",
    "        self.epsilon = round(self.epsilon * self.decay, 10)\n",
    "\n",
    "        return action\n",
    "\n",
    "class QLAgent:\n",
    "    def __init__(self, action_space, alpha=0.5, gamma=0.8, exploration_strategy=EpsilonGreedy()):\n",
    "        self.position = (0,0)\n",
    "        \n",
    "        self.state = self.state_representation()\n",
    "        self.action_space = action_space\n",
    "        self.action = 0\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.q_table = {self.state: [0] * len(self.action_space)}\n",
    "        self.exploration = exploration_strategy\n",
    "\n",
    "    def state_representation(self):\n",
    "       return str(self.position[0]) + str(self.position[1])\n",
    "\n",
    "    def escolher_acao(self):\n",
    "        return self.exploration.choose(self.q_table, self.state, self.action_space)\n",
    "    \n",
    "    def recompensa(self):\n",
    "        return ambiente[self.position]\n",
    "    \n",
    "    def move_agent(self):\n",
    "        x, y = self.position\n",
    "        acao = self.action_space[self.action]\n",
    "        \n",
    "        if (acao == 'up' and x != 0):\n",
    "            x -= 1\n",
    "        elif(acao == 'down' and x != ambiente.shape[0]-1):\n",
    "            x += 1\n",
    "        elif(acao == 'left' and y != 0):\n",
    "            y -= 1\n",
    "        elif (acao == 'right' and y != ambiente.shape[1]-1):\n",
    "            y += 1\n",
    "\n",
    "        self.position = (x, y)\n",
    "            \n",
    "    def end_epsodio(self):\n",
    "        if self.position in [(1,5), (4,5), (5,5)]:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def new_epsodio(self):\n",
    "        self.position = (0, 0)\n",
    "        \n",
    "    def learn(self, v=False):\n",
    "        \n",
    "        self.state = self.state_representation()\n",
    "\n",
    "        if self.state not in self.q_table:\n",
    "            self.q_table[self.state] = [0] * len(self.action_space)\n",
    "    \n",
    "        p = self.position    \n",
    "        self.action = self.escolher_acao()\n",
    "        self.move_agent()\n",
    "        reward = ambiente[self.position]\n",
    "        \n",
    "        \n",
    "        proximo_estado = self.state_representation()\n",
    "        \n",
    "        if proximo_estado in self.q_table:\n",
    "            max_new_state = max(self.q_table[proximo_estado])\n",
    "        else:\n",
    "            self.q_table[self.state] = [0] * len(self.action_space)\n",
    "            max_new_state = 0\n",
    "                \n",
    "        #                             Q(s, a) = (1 - alpha) * Q(s, a) + alpha(r + Y * Q(s+1, a))\n",
    "        self.q_table[self.state][self.action] = (1 - self.alpha) * self.q_table[self.state][self.action] + self.alpha * (reward + self.gamma * max_new_state)\n",
    "        \n",
    "        \n",
    "        if v:\n",
    "            char = ''\n",
    "            \n",
    "            if self.action_space[self.action] == 'up':\n",
    "                char = '^'\n",
    "            elif self.action_space[self.action] == 'down':\n",
    "                char = 'v'\n",
    "            elif self.action_space[self.action] == 'left':\n",
    "                char = '<'\n",
    "            elif self.action_space[self.action] == 'right':\n",
    "                char = '>'\n",
    "            \n",
    "            caminho[p] = char\n",
    "        \n",
    "        return self.end_epsodio()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agente = QLAgent(['up', 'down', 'left', 'right'], alpha=0.5, gamma=0.1, exploration_strategy=EpsilonGreedy())\n",
    "interacoes = 1000\n",
    "end = True\n",
    "caminho = draw.copy()\n",
    "\n",
    "while interacoes > 0:\n",
    "    while end:\n",
    "        end = agente.learn()\n",
    "    end = True\n",
    "    agente.new_epsodio()\n",
    "    interacoes -= 1\n",
    "\n",
    "   \n",
    "while end:\n",
    "       end = agente.learn(v = True)\n",
    "\n",
    "caminho\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}